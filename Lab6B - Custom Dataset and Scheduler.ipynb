{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBjhQ7aWusA9"
   },
   "source": [
    "# Lab 6B - Custom Dataset and Scheduler\n",
    "\n",
    "In this lab, we shall learn to implement the following two things:\n",
    "1. Build a custom dataset with your own data\n",
    "2. Perform learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ajv2a-hjvLWR"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GX_32H05vW1V"
   },
   "outputs": [],
   "source": [
    "cd '/content/gdrive/My Drive/UCCD3074_Lab6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQrbGZMyeuHn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbk6jlahxyvm"
   },
   "source": [
    "---\n",
    "# 1. The Hymenoptera Dataset\n",
    "\n",
    "The problem weâ€™re going to solve today is to train a model to classify **ants** and **bees**. We have about 120 training images each for ants and bees. There are 75 validation images for each class. Usually, this is a very small dataset to generalize upon, if trained from scratch. Since we are using transfer learning, we should be able to generalize reasonably well. This dataset is a very small subset of imagenet.\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/sphx_glr_transfer_learning_tutorial_001.png\" width=40%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmN2tS3Zu-s5"
   },
   "outputs": [],
   "source": [
    "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
    "!unzip -q hymenoptera_data.zip\n",
    "rm 'hymenoptera_data/train/ants/imageNotFound.gif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSp2QCk_Kelk"
   },
   "source": [
    "Take a look at the folder `hymenoptera_data`. It has the following directory structure:\n",
    "```\n",
    "hymenoptera_data\\\n",
    "   train\\\n",
    "      ants\\\n",
    "      bees\\\n",
    "   val\\\n",
    "      ants\\\n",
    "      bees\\\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GkScgd9HLAta"
   },
   "source": [
    "# 2. Writing custom dataset\n",
    "\n",
    "## 2.1 The Abstract `Dataset` Class\n",
    "\n",
    "PyTorch provides `torch.utils.data.Dataset` to allow you create your own custom dataset. `Dataset` is an abstract class representing a dataset. Your custom dataset should inherit `Dataset` and override the following methods:\n",
    "\n",
    "* **`__len__`** so that len(dataset) returns the size of the dataset.\n",
    "* **`__getitem__`** to support the indexing such that dataset[i] can be used to get ith sample\n",
    "\n",
    "The following code creates a dataset class for the hymenoptera dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzlzMcnhusBB"
   },
   "outputs": [],
   "source": [
    "#  ... your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhoHSdu-L1Mh"
   },
   "source": [
    "* **`__init__`**: Get the filenames of all training samples (`self.data`) and their corresponding labels (`self.labels`)\n",
    "    * Line 10: \n",
    "    <br> If `transform` is passed by the user, all images would be transformed using this pipeline when they are read in `__getitem__` later. \n",
    "    * Line 11: \n",
    "    <br> There are 2 classes in the dataset (0: ants, 1: bees)\n",
    "    * Line 14-21: \n",
    "    <br> For each of the class (line 14), get the names of all the files in their class directories (line 19) and update `self.data` (line 20) and `self.labels` (line 21).\n",
    "\n",
    "* **`__getitem__`**: Read the image and label. Transform the image if required. Return the transformed image and label.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Notes**: *While it is possible to load all images in the `__init__`, we have choosen to read the images only when requested by the user in `__getitem__`. This is more memory efficient because all the images are not stored in the memory at once but read as required. This is the normal setup when the dataset is huge.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgaMCD-iPPeU"
   },
   "source": [
    "### 2.2 Instantiating `HymenopteraDataset`\n",
    "\n",
    "Let's instantiate the HymenopteraDataset and look into one of its sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1ysiMhZusBH"
   },
   "outputs": [],
   "source": [
    "#  ... your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rXLsQhvmPoNN"
   },
   "source": [
    "* `Line 1`: When creating `trainset`, the function `__init__` will be called to populate `trainset.data` and `trainset.labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BMUYASc7Pcpf"
   },
   "source": [
    "Next, we look into the first sample in the label. Since we did not transform the image, we can still display the image without undoing the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gN_YbyzfusBN"
   },
   "outputs": [],
   "source": [
    "#  ... your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5P774k287cvX"
   },
   "source": [
    "---\n",
    "\n",
    "# 3.1 Customizing ResNet18 for Binary Classification\n",
    "\n",
    "Now, customize ResNet18 (`torchvision.models.resnet18`) to build a classifier to differentiate between *ants* vs *bees*.  \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://www.researchgate.net/profile/Paolo_Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture_W640.jpg\" width=40%>\n",
    "</center>\n",
    "\n",
    "The ResNet18 receives an input of size 18x18 and it outputs a vector of 1000 dimensions since it was pretrained on the ImageNet with 1000 object categories.\n",
    "\n",
    "In PyTorch implementation, the layers are defined as:\n",
    "\n",
    "|**Layer Name**| **Name in `torchvision.models.resnet18`** |\n",
    "|:---:|:---:|\n",
    "|conv1 | conv1, bn1, relu, maxpool |\n",
    "|conv2_x | layer 1 |\n",
    "|conv3_x | layer 2 |\n",
    "|conv4_x | layer 3 |\n",
    "|conv5_x | layer 4 |\n",
    "|average pool | avgpool |\n",
    "|fully connected  | fc |\n",
    "|softmax          |  Not implemented. Softmax is implemented <br> in `CrossEntropy` loss|\n",
    "\n",
    "#### Exercise:\n",
    "<font color=blue>\n",
    "Customize <i>resnet18</i> for a binary classification task. Replace the <i>fc</i> layer with the following layers with the following two layers:\n",
    "<br>\n",
    "<br>\n",
    "<li> nn.Linear(512, 1) \n",
    "<li> nn.Sigmoid()\n",
    "<br>\n",
    "<br>\n",
    "You may group them into a `nn.Sequential` module.\n",
    "\n",
    "Expected result:\n",
    "</font>\n",
    "```\n",
    "    ResNet(\n",
    "        (conv1): ...\n",
    "        (bn1): ...\n",
    "        (relu): ...\n",
    "        (maxpool): ...\n",
    "        (layer1): ...\n",
    "        (layer2): ...\n",
    "        (layer3): ...\n",
    "        (layer4): ...\n",
    "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        (fc): Sequential(\n",
    "            (0): Linear(in_features=512, out_features=1, bias=True)\n",
    "            (1): Sigmoid()\n",
    "        )\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZQ4jY_7usBn"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# START OF CODE: Customize resnet18 for a binary classification task\n",
    "################################################################################\n",
    "#  ... your code here ...\n",
    "################################################################################\n",
    "#      END OF CODE         \n",
    "################################################################################\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttnbw-1g79-j"
   },
   "source": [
    "To train the model, we shall finetune the the top layers, namely `layer4` and `fc` layers. Freeze all other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3JH05pxusBu"
   },
   "outputs": [],
   "source": [
    "freeze_layers = [\"layer4\", \"fc\"]\n",
    "\n",
    "#################################################################\n",
    "# Freeze all the layers except for the layers defined in \n",
    "# freeze_layers  (5 lines)\n",
    "#################################################################\n",
    "#  ... your code here ...\n",
    "#################################################################\n",
    "#               END OF CODE\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to check if you have set your model correctly. If you have configured the layers correctly, all the weights and biases for `layer4` and `fc` would be `True` whereas those for the remaining layers would be `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, \":\", param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCZsNtP_Wj2N"
   },
   "source": [
    "---\n",
    "\n",
    "# Training the Model\n",
    "\n",
    "Now we are ready to train the model. In the following, we define the transformation, set up our optimizer and scheduler, and then define the training function before training the model.\n",
    "\n",
    "Define the transformation function to augment the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1akxO6XwusBT"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# transform the model\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IA3iYspBW-MF"
   },
   "source": [
    "Load the dataset with the defined transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvbtgpddW2Ii"
   },
   "outputs": [],
   "source": [
    "trainset = HymenopteraDataset(\"./hymenoptera_data/train\", transform=train_transform)\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_v7Eo-f8Glt"
   },
   "source": [
    "Set up the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s72JIfa4XJVj"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bN4jKoEleXHT"
   },
   "source": [
    "Set up the scheduler. In the following, we are going to use the **step decay schedule**. We shall drop the learning rate by a factor of 0.1 every 7 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qn9KLFGJXIf1"
   },
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5cJwIqTefkI"
   },
   "source": [
    "Train the model. We pass both the dataloader, optimizer and scheduler into the function. In order to reduce the learning rate according to the schedule, you must **`scheduler.step`** at the end of every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_90I4p7ZusB0"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, scheduler, num_epochs):\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    # transfer model to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "    \n",
    "    # set to training mode\n",
    "    net.train()\n",
    "\n",
    "    # train the network\n",
    "    for e in range(num_epochs):    \n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_count = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "            labels = labels.reshape(-1, 1).float()\n",
    "            \n",
    "            # Clear all the gradient to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # transfer data to GPU\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # forward propagation to get h\n",
    "            outs = net(inputs)\n",
    "        \n",
    "            # compute loss \n",
    "            loss = F.binary_cross_entropy(outs, labels)\n",
    "\n",
    "            # backpropagation to get dw\n",
    "            loss.backward()\n",
    "\n",
    "            # update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # get the loss\n",
    "            running_loss += loss.item()\n",
    "            running_count += 1\n",
    "\n",
    "        # compute the averaged loss in each epoch\n",
    "        train_loss = running_loss / running_count\n",
    "        running_loss = 0. \n",
    "        running_count = 0.\n",
    "        print(f'[Epoch {e+1:2d}/{num_epochs:d} Iter {i+1:5d}/{len(trainloader)}]: train_loss = {train_loss:.4f}')       \n",
    "\n",
    "        # Update the scheduler's counter at the end of each epoch\n",
    "        ... your code here ...\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vcc7mg1Fe-y4"
   },
   "source": [
    "Now we are ready to train our model. We should expect training loss of about 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XAJtwbR8eu9"
   },
   "outputs": [],
   "source": [
    "train(model, trainloader, optimizer, scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8t3QwbxusB6"
   },
   "source": [
    "# Evaluate the model\n",
    "\n",
    "The following code then evaluates the model. The expected accuracy is around 93.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVdkt3US_fhI"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, testloader):\n",
    "    # set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # running_correct\n",
    "    running_corrects = 0\n",
    "    running_count = 0\n",
    "\n",
    "    for inputs, targets in testloader:\n",
    "        \n",
    "        # transfer to the GPU\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        \n",
    "        # perform prediction (no need to compute gradient)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs > 0.5\n",
    "            running_corrects += (predicted.view(-1) == targets).sum().double()\n",
    "            running_count += len(inputs)\n",
    "            print('.', end='')\n",
    "\n",
    "    print('\\nAccuracy = {:.2f}%'.format(100*running_corrects/running_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o48-ydGZyoe5"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# transform the model\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "testset = HymenopteraDataset(\"./hymenoptera_data/val\", transform=val_transform)\n",
    "testloader = DataLoader(testset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "evaluate(model, testloader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab6B - Custom Dataset and Scheduler",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
